---
title: "Workflow to Model the Urban Heat Island Effect of the City of Bern"
author: "Nils Tinner, Patrick Bigler"
date: "12-01-2023"
output:
  html_document:
    toc: yes
    toc_float: yes
    number_sections: yes
    latex_engine: xelatex
editor_options:
  markdown:
    wrap: 75
bibliography: references.bib
---

Course: Proseminar in Applied Geo-Data Science at the University of Bern
(Institute of Geography)

Supervisor: Prof. Dr. Benjamin Stocker

Adviser: Dr. Koen Hufkens, Dr. Laura Marques, Pepa Aran

Further information: <https://geco-bern.github.io/agds_proseminar/>

[Do you have questions about the workflow? Contact the
authors:]{.underline}

Tinner Nils (nils.tinner\@students.unibe.ch)

-   Open Science and reproducibility

-   Preprocessing the data

-   Advanced models (XGB and neuronal network)

Bigler Patrick (patrick.bigler1\@students.unibe.ch)

-   Model implementation and calculations

-   Model tuning

-   Model evaluation

-   Visualize the key findings

-   Structure and design of this markdown and the workflow

\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--

# Introduction

Anthropogenic climate change is expected to increase the amount, intensity,
and duration of heat waves [@burger2021]. The urban heat island (UHI)
effect further amplifies this trend in urban environments [@burger2021],
[@gubler2021], [@wicki2018]. The UHI effect is expressed by higher air
temperatures in urban areas compared to rural areas in the region (Oke et
al. 2006). The effect is highest during night, as the emission of longwave
radiation in urban environments is impaired and sensible heat fluxes are
enhanced, whilst latent fluxes are reduced [@burger2021], [@gubler2021].
People living in urban areas are thus highly affected by the UHI effect via
thermal stress [@burger2021], [@wicki2018]). Given that more than 75% of
the Central European population lives in urban areas, the increasing trend
poses one of the major weather threats to people in urban environments
[@wicki2018]. Studying spatial temperature variabilities in urban areas is
therefore crucial to implement adaptation measures to minimize effects on
human health and the environment [@burger2021].

To capture small-scale temperature changes in these climatically complex
areas, high spatial resolution measurement networks are needed. However,
automated weather stations (AWS) are scarce due to their high costs. To
tackle this problem, @gubler2021 developed a new type of low-cost
measurement devices (LCDs). The LCD consists of a temperature logger and a
custom-made radiation shield that is naturally ventilated. 79 LCDs were
installed in the city of Bern, Switzerland in 2018 @gubler2021. In
@gubler2021 reported an overestimation of hourly mean temperature
measurements by the LCDs (0.61 °C - 0.93 °C) compared to the reference
station (AWS) during daytime (06:00 -- 22:00). During night-time (22:00 --
06:00), differences were much lower or even negative (between -0.12 °C and
0.23 °C). But not only the LCD temperature and the anomaly between the LCDs
and the AWS is interesting, but also the temperature distribution of the
entire region of Bern, shown on a map.

In spring 2023, Nils Tinner generated a map of the current LCDs temperature
in the city of Bern based on the study of @burger2021. He improved the map
in June 2023 by also using geospatial data from the study of @burger2021 to
generate a map showing the spatial temperature distribution of the city of
Bern. The approach was a classic multivariate linear regression model. As
the model only knows the current temperature distribution, its scope and
statistical power are limited. But because both @burger2021 and @gubler2021
showed that the city of Bern is affected by the urban heat island effect it
is crucial to know more about the urban heat island effect in Bern. This
fact and the limited power of the first map from Nils Tinner motivated us
to investigate the urban heat island once again.

## Objectives and Research Questions

Because @burger2021 and @gubler2021 only used a multiple linear regression
approach to model the urban heat island effect in the city of Bern, in this
study we aim to calculate our own models by using a classic approach
(multiple linear regression model) and machine learning approaches
(k-nearest neigbors (knn) and random forest). For model calculations, we
use partial the same data as the study of @burger2021 but note that this
study is not a redoing of his study. After the model calculation we compare
our models with each other and use the best to model to visualize our
findings in a map. Ideally, this allows us to investigate the urban heat
island effect in the city of Bern. This leads to our four research
questions:

1.  Are the two machine learning approaches (knn and random forest)
    reasonable approaches for modeling the urban heat island effect in the
    city of Bern in terms of explaining the variance ($R^2$), the precision
    (RMSE) and the accuracy (bias)?
2.  Are the machine learning approaches superior to a multiple regression
    model in terms of explaining the variance ($R^2$), the precision (RMSE)
    and the accuracy (bias)?
3.  Can a meaningful map be generated from the best model that shows the
    spatial distribution of the temperature anomaly?
4.  What can be said from this modeling about the modeling of @burger2021
    in terms of explaining the variance ($R^2$), the precision (RMSE) and
    the accuracy (bias)?

However, this study does not aim to provide a new and reliable method for
modeling the UHI effect in the city of Bern. Nevertheless, it is intended
to show that the machine learning approaches examined are promising and
that the full potential has not yet been reached.

## How this Workflow Works

In the Data and Methodology section you will see that we work with a large
amount of data. This means the computational time could be very high. To
address this issue we implemented different workflows within this markdown.
If you change the input of the functions in the first code chunk, you will
run the workflow in a different mode. Figure 1 gives you a overview about
the default mode and all other options you have:

SCHEMATIC OF THE DIFFERENT WORKFLOWS

Please note that the default version is only guaranteed until the end of
February 2024. After that, you have to change the input ofl function xx
from TRUE to FALSE.

### Packages

This code chunk install and load all packages you need for reproduce this
project. If you think you need another package as well, then write it into
the vector 'packages' and run the code again.

```{r Load the Packages needed, message=FALSE, warning=FALSE, include=FALSE}
# Decide which packages you need. For this Project you need the following:
packages <- c("influxdbclient","ggplot2","tidyverse","lubridate","raster",
              "dplyr","googledrive","caret","rgdal","keras","vip","parsnip",
              "workflows","tune","dials","stringr","terra","stars","sf","plyr",
              "doParallel", "foreach", "terrainr","starsExtra", "pdp", "recipes", 
              "tidyterra","shiny", "xgboost", 'kableExtra')
```

### Change the Workflow

This subsection generate your basic .csv file (it is called 'sCombined') in
a interactive way. Therefore, you have to navigate through some questions.
First, it will check whether a Combined.csv file already exists in the
corresponding folder. If it, then it will read in. If not, then three
questions will follow. Here, you can see those questions and an explanation
what the answers mean for the further workflow:

1.  You have a Combined.csv file already. Would you like to redo the
    proceeding?

    If you answer with 'yes', then will guided through the following
    questions and your Combined.csv file will be rewritten. If you answer
    with 'no', then it will read your existing file and you will directly
    jump to the model section.

2.  Do you want to generate all data by yourself? (It may takes up to 12
    hours)

    If you answer with 'yes', all data will be downloaded and processed
    again. It may takes several hours. If you answer with 'no', then you
    will be asked a second question:

3.  Do you want to proceed in a demo version?

    If you answer with 'yes', it will download all data from a dropbox
    account and generate a .csv file which contains 5 % of the data. With
    this option, all calculations can be done in max. 5 minutes. If you
    answer with 'no', then it will download all data from a dropbox account
    and generate a .csv file which contains all data. With this option, the
    duration for some calculations can exceed 30'.

```{r Choose your workflow mode, message=FALSE, warning=FALSE, include=FALSE}

knit <- "y" #CHANGE HERE FOR EXPLORATION OF REPORT IN R

if (knit == "y") {
  model_demo <- "y"
  advanced_models <- "n"
# Load the R script to install and load all the packages from above
source("../R/load_packages.R")
source("../R/demo_download.R") #directly download
source("../R/data_combination.R") #and process
data_combination()
}else{
# Load the R script to install and load all the packages from above
source("../R/load_packages.R")  
# Load the R script to start the workflow
source("../R/Processing_Brain.R")
preprocessing()

source("../R/model_training_brain.R")
model_training_brain()
}


combined <- read_csv("../data/Combined.csv") |>
  mutate(temperature = temperature-temp) |>
  drop_na()

  if (model_demo == "y") {
    # choose 5% of the data randomly
    combined <- dplyr::slice_sample(combined,prop = .05) 
  }

# Set seed for reproducibility
set.seed(123)

# (pseudo) random sample
loggers_test <- sample(unique(combined$Log_Nr), 10)

# Generate a test set
combined_test <- combined |> 
  filter((Log_Nr %in% loggers_test))

# Generate a training set
combined_train <- combined |> 
  filter(!(Log_Nr %in% loggers_test))

```

# Data and Methodology

In this section, we will first introduce the data used. After that, we will
present the methodology. For a better understanding, we have split the
methodology section into two parts. The first one presents the preparation
and (pre)processing of the data. The second part is dedicated to the
implementation of the models.

## Data

Temperature data for the years 2019-2022 from the network of the city of
Bern is used. This is a numerical data set of the 3 m temperature in 104
locations, with a temporal resolution of 10 minutes for all LCDs. How many
LCD are aktive depends on the year but 55 LCDs are active over the entiere
time period. The network data is publicly available on BORIS. We use
additional data from the AWS at Zollikofen, as it is the official
meteorologic station of Bern. The five meteorological variables (2m
temperature, precipitation, radiation and wind (direction and speed)) with
a temporal resolution of 10 minutes for the years 2019-2022 will be used as
well as the timestamp. Data of temperature and precipitation of the
previous six and twelve hours, and one, three and five days will also be
fed into the model. This data is uploaded to the repository to ensure
availability since the IDAWEB-data service is open for scientific use but
not completely open access. To show small scale urban patterns of
temperature distributions, geospatial data as shown in @burger2021 is used.
These are cantonal land use classes as well as federal geospatial data. All
of the data is spatially averaged to obtain the layers most effective as
shown in @burger2021. The federal and cantonal data is directly downloaded
from the web into R. Table 1 provides a brief overview of the data we will
use.

| Variable                                                             | Variable Typ     | Resolution / [used]                                       |
|----------------------------------|-------------------|---------------------|
| 2m Temperature in °C [Zollikofen] for the time period 2019 - 2022    | Meteorological   | 15 minutes / [1h mean, 6,12,24,72,120 hours rolling mean] |
| Precipitation in mm [Zollikofen] for the time period 2019 - 2022     | Meteorological   | 15 minutes / [1h mean, 6,12,24,72,120 hours rolling sum]  |
| Radiation in $W*m^{-2}$ [Zollikofen] for the time period 2019 - 2022 | Meteorological   | 15 minutes / [1h mean]                                    |
| Windspeed in $m*s^{-1}$ [Zollikofen] for the time period 2019 - 2022 | Meteorological   | 15 minutes / [1h mean]                                    |
| Winddirection in ° [Zollikofen] for the time period 2019 - 2022      | Meteorological   | 15 minutes / [1h mean]                                    |
| Buildings                                                            | Land use class   | [25m / 150m / 1000m]                                      |
| Open Space Forest                                                    | Land use class   | [25m / 150m / 1000m]                                      |
| Open Space Garden                                                    | Land use class   | [25m / 150m / 1000m]                                      |
| Open Space Sealed                                                    | Land use class   | [25m / 150m / 1000m]                                      |
| Open Space Agriculture                                               | Land use class   | [25m / 150m / 1000m]                                      |
| Open Space Water                                                     | Land use clas    | [25m / 150m / 1000m]                                      |
| Vegetation Height                                                    | Geospatial Layer | [25m / 150m / 1000m]                                      |
| Mean Building Heights                                                | Geospatial Layer | [25m / 150m / 1000m]                                      |
| Slope                                                                | Geospatial Layer | [25m / 150m / 1000m]                                      |
| Digital Elevation Model (DEM)                                        | Geospatial Layer | [25m / 150m / 1000m]                                      |
| Climate Network in °C [80 LCDs] in year 2019                         | Meteorological   | 10 minutes / [1h mean]                                    |
| Climate Network in °C [67 LCDs] in year 2020                         | Meteorological   | 10 minutes / [1h mean]                                    |
| Climate Network in °C [67 LCDs] in year 2021                         | Meteorological   | 10 minutes / [1h mean]                                    |
| Climate Network in °C [81 LCDs] in year 2022                         | Meteorological   | 10 minutes / [1h mean]                                    |

: **TABLE 1:** Overview of the predictors used for modeling.

To evaluate...LCDs...target?.......Because we also want to show a possible
application of such models the best model will be used to show spatial
temperature distributions for a possible day as a map.

## Methodology: Preparation

In this section, all preparations for modeling are performed.The second
subsection aims to generate the basis data frame (Combined.csv) in a
interactive way when run with knit = "f". First, tiff-files are generated.
Either the files are downloaded directly from a remote repository, which is
the case when knitting. Alternatively, the tiff files are generated by
downloading and processing of the tiff files as raw data from open source.
Processing can be performed with the layer resolutions by Burger et al.
2019 which corresponds to one predictor per variable in !!!table one!!!.
Alternatively and preferably the tiffs are all processed by the resolutions
in !!!Table 1!!!. This results in three predictors per variable in !!!table
1!!!.

### Variable Selection

First, a variable selection was carried out (Markdown::
Variable_Selection.rmd). This was only expored for the predictors in
TABLE.1!!! since layers by @burger2021 were already reduced and selected.
The variable selection with Boruta resulted after removal of variable that
should be removed not due to relevance reasons but other reasons (!!!Table
2!!!), that all variables are relevant. Further variable selection was
explored, but no definitive answers were reached. For that reason, all
generated predictors are used.

Table two provides a brief overview of why certain variables were rejected.
Based on this selection, a formula is now generated, which is processed
into a recipe. This is now the basis for creating the models.

| Variable which is not a predictor | Reason                                                                          |
|------------------------|---------------------------------------------------|
| Log_Nr                            |                                                                                 |
| temperature                       | because this is the target                                                      |
| timestamp, year, month, day, hour | because it is controversial whether time and date should be used as predictors. |
| NORD_CHTOP, OST_CHTOP             | Coordinates are not used                                                        |
| LV_03_E, LV_03_N                  | Coordinates are not used                                                        |

: **TABLE 2:** Overview about the reasons why a variable/column were
rejected as a predictor

### Model Recipe

```{r Predictors and Recipe, echo=FALSE, message=FALSE, warning=FALSE}
# Take all column-names you need as predictors from the combined file
predictors <- combined |>
  # select our predictors (we want all columns except those in the select() function)
  dplyr::select(-c(Log_Nr,temperature,timestamp,Name,NORD_CHTOP,OST_CHTOPO,
                   year,month,day,hour,LV_03_E,LV_03_N)) |>
  colnames()

# Define a formula in the following format: target ~ predictor_1 + ... + predictor_n
formula_local <- as.formula(paste("temperature","~", paste(predictors,collapse  = "+")))
  
# Make a recipe which can be used for the lm, KNN, and Random Forest model
pp <- recipes::recipe(formula_local,
                      data = combined_train) |>
    # Yeo-Johnsen transformation (includes Box Cox and an extansion. Now it can handle x ≤ 0)
    recipes::step_YeoJohnson(all_numeric(), -all_outcomes()) |> 
    # subsracting the mean from each observation/measurement
    recipes::step_center(recipes::all_numeric(), -recipes::all_outcomes()) |>
    # transforming numeric variables to a similar scale
    recipes::step_scale(recipes::all_numeric(), -recipes::all_outcomes())
```

## Methodology: Modelling

Here, you can select the model that will be used to eventually estimate the
map's spatial temperature distribution. You will find that the model with
the random forest approach shows the best performance, which is why it was
used for the map.

### Basic Models implementation

#### Implementation of the Linear Regression Model

The lm-model is a classic multiple linear regression model. The function
need a recipe (pp) and train data as inputs. There is no possibility for
tuning the model.

```{r Calculate lm-model, echo=FALSE, message=FALSE, warning=FALSE}
# Load the R script to calculate a lm model
source("../R/lm_model.R")

# The function needs the recipe and a dataset which can be used for model training
lm_model <- LM_Model(pp, combined_train)
```

#### Implementation of the KNN Model

The KNN-model can be very time intensive. We use the DoParallel Package for
that. Please make sure, that your device do not anything else.

The KNN-model uses the recipe (pp) and training data as inputs. The
function calculate a KNN-Model with the recipe and uses 3 cross validations
by logger numbers. Further, you have the option for tuning the
hyper-parameter k by using tuning=TRUE/FALSE. Note that this can be very
time intensive. We have done it already and the function will use k = 10 as
a default. If you want to do it again, change tuning = TRUE and the
function will tune the model for k = c(8, 9, 10, 11, 12). Moreover, the
function also has a safety feature implemented. Because the computing time
for a KNN-model can be very high, the data input is limited to 100,000
rows. The adjustment takes place automatically.

```{r Calculation of the knn-model, echo=FALSE, message=FALSE, warning=FALSE}
# Load the R script to calculate a KNN model
source("../R/knn_model.R")

# The function needs the recipe and a dataset which can be used for model training
knn_model <- KNN_Model(pp = pp, training_data =  combined_train, tuning = FALSE)
```

#### Implementation of the Random Forest Model

The random forest-model can be very time intensive. We use the DoParallel
Package for that. Please make sure, that your device do not anything else.

The function calculate a random forest-model with the recipe and uses 3
cross validations by logger numbers. Further, you have the option for
tuning the hyper-parameters by using tuning=TRUE/FALSE. Note that this can
be very time intensive. We have done it already and the function will use
mtry = number of predictors/3 and min.node.size = 5 as default.

```{r Calculation of the random forest-model, echo=FALSE, message=FALSE, warning=FALSE}
# Load the R script to calculate a random forest model
source("../R/random_forest.R")

# The function needs the recipe and a dataset which can be used for model training
random_forest_model <- random_forest(pp, combined_train, tuning = F)
```

### Advanced Models implementation

#### Implementation of the XGB Model

Hyperparamater:

```{r}

if(advanced_models == "y"){
source("../R/XGB.R")
# type of task we want to evaluate

#this model always tunes...
xgb_model <- xgb(data_train = combined_train,formula = formula_local) }
```

#### Implementation of the neuronal network

```{r}

if(advanced_models == "y"){
  source("../R/neural_network.R")
  #tensorflow::install_tensorflow() may need to be run...
  nn_model <- neural_network(combined_train)
#preprocessing needed for test imput of nn
  predictors_nn <- combined_test |>
  dplyr::select(all_of(predictors))
temperature <- combined_test |>
  dplyr::select(temperature)

# Normalize/Scale the predictors using dplyr
scaled_predictors <- predictors_nn|>
  mutate(across(everything(), scale))

# Combining the scaled predictors with the temperature into a single data frame
processed_data <- cbind(scaled_predictors, temperature)




test_data <- processed_data

  
test_features <- test_data|> select(-temperature)
test_labels <- test_data|> pull(temperature)
}  
```

# Results

## Basic Models

### Evaluation of the lm-model

Here we evaluate the lm-model. We use our evaluate_function(). The return
will be a list; we can choose which part of the evaluation we want access
to (see table 2).

```{r Evaluation of the lm-model, echo=FALSE, message=FALSE, warning=FALSE}
# Load the R script to evaluate the model
source("../R/evaluation.R")
# The function will return a list
evaluation <- evaluation_function(combined_test, combined_train, lm_model)

# If we want our metrics in table, we chose the first element of the list
evaluation[[1]]
# If we want a visualization of the training and test set
evaluation[[2]]
# Boxplot for each logger station (24h)
evaluation[[3]]
# Boxplot for each hour of the day
evaluation[[4]]
```

### Evaluation of the knn-model

Here we evaluate the KNN-model. We use our evaluate_function() again. The
return will be a list; we can choose which part of the evaluation we want
access to (see table 2).

```{r Evaluation of the knn-model, echo=FALSE, message=FALSE, warning=FALSE}
# Load the R script to evaluate the model
source("../R/evaluation.R")

# Function call
evaluation <- evaluation_function(combined_test, combined_train, knn_model)

# If we want our metrics in table, we chose the first element of the list
evaluation[[1]]
# If we want a visualization of the training and test set
evaluation[[2]]
# Boxplot for each logger station
evaluation[[3]]
# Boxplot for each hour of the day (24h)
evaluation[[4]]
```

### Evaluation of the random forest-model

Here we evaluate the random forest-model. We use our evaluate_function()
again. The return will be a list; we can choose which part of the
evaluation we want access to (see table 2).

```{r Evaluation of the random forest-model, echo=FALSE, message=FALSE, warning=FALSE}
# Load the R script to evaluate the model
source("../R/evaluation.R")

# Function call
evaluation <- evaluation_function(combined_test, combined_train, random_forest_model)

# If we want our metrics in table, we chose the first element of the list
evaluation[[1]]
# If we want a visualization of the training and test set
evaluation[[2]]
# Boxplot for each logger station (24h)
evaluation[[3]]
# Boxplot for each hour of the day
evaluation[[4]]
```

## Advanced Models

### Evaluation of the xgb-model

Achtung: If statement implementieren!

```{r}

if(advanced_models == "y"){

source("../R/evaluation.R")

# Function call
evaluation <- evaluation_function(combined_test, combined_train, xgb_model)

# If we want our metrics in table, we chose the first element of the list
evaluation[[1]]
# If we want a visualization of the training and test set
evaluation[[2]]
# Boxplot for each logger station (24h)
evaluation[[3]]
# Boxplot for each hour of the day
evaluation[[4]]
}
```

### Evaluation of the neuronal network

```{r}

if(advanced_models == "y"){  
  # Evaluate the model
evaluation <- nn_model|> evaluate(as.matrix(test_features), test_labels)
cat("Mean Absolute Error on Test Data:", evaluation, "\n")

# Make predictions
combined_test$nn_prediction <- nn_model|> predict(as.matrix(test_features))


cor(combined_test$nn_prediction,combined_test$temperature)
}
```

## Summary of the Key Findings

### Overview about the Evaluation of the Models

| Model             | RSQ [Test set] | RMSE [Test set] | MAE [Test set] | Bias [Test set] |
|---------------|---------------|---------------|---------------|---------------|
| Linear Regression |                |                 |                |                 |
| KNN               |                |                 |                |                 |
| Random Forest     |                |                 |                |                 |
| XGB Boost         | \-             | \-              | \-             | \-              |
| Neuronal Network  | \-             | \-              | \-             | \-              |

: **TABLE 4:** Overview of the evaluation of the models with data from
Burger et al. (2019).

To fully implement the Open Sciences approach, the models can be computed
using the following code chunks. Further, for every model, a short synopsis
of the optimized hyperparameters is given. It must therefore be decided
before running the code chunk whether the hyperparameters determined by us
are to be used or whether the hyperparameters are to be optimized.

| Element of the list | What do you find                                                                               |
|-------------------|--------------------------------------------------------|
| 1                   | returns a table with the main metrics (RSQ, RMSE, MAE and Bias)                                |
| 2                   | retunrs a visualization of the model (Training and Test set) and shows RSQ, RMSE and the bias. |
| 3                   | returns a boxplot for each logger station (24h)                                                |
| 4                   | returns a boxplot for each hour of the day                                                     |

: **TABLE 2:** Overview of the returned list of the evaluation function

The aim of this project is the comparison of machine learning techniques to
a linear regression. Further, we want to explore the superior of machine
learning compared to a linear regression. Table 3 gives you an overview
about our results, if you use the entire 'combined' data set. You see, that
both KNN and random forest are superior compared to the linear regression
model.

The random forest model explains about 73% of the variance. The RSME is
about 0.63 °C. Note that the error of a single LCD in the climate network
of the city of Bern is about 1.5°C (see Burger et all 2019). Further we can
see, that data scattering is about 0.2°C lower than for a KNN- or lm-model
(accuracy). The bias is for all models about 0.07°C (systematic error /
precision). It is positive and therefore our models overestimate the
temperature (see evaluation and access the second element of the list).

The XGB Boost and the neuronal network are additional and should show you,
that there are further techniques which could be explored. But those model
we did not taken into account.

| Model                | RSQ [Test set] | RMSE [Test set] | MAE [Test set] | Bias [Test set] |
|---------------|---------------|---------------|---------------|---------------|
| Linear Regression    | 0.47           | 0.86 °C         | 0.67 °C        | 0.06 °C         |
| KNN [reduced to 13%] | 0.51           | 0.84 °C         | 0.65 °C        | 0.07 °          |
| Random Forest        | 0.73           | 0.63 °C         | 0.46 °C        | 0.07 °C         |
| XGB Boost            | \-             | \-              | \-             | \-              |
| Neuronal Network     | \-             | \-              | \-             | \-              |

: **TABLE 3:** Overview of the evaluation of the models in the regular
mode.

As mentioned, the model calculation can be very time intensive. Table 4
shows the results for approach with reduced data. Overall we can say, that
the models perform less. All values are lesser than in table 3. Note the
high bias for the random forest. The model highli overestimate the
temperature. We do not have an explanation for this. May be there is a
problem with the reducing process. If we only use 5% of our data, then we
lose a lot of information. If we lose all information about a certain
logger station but the model predict this station, the it could b that the
model perfoms worse. But we are not sure and more investigations are
needed. But as a conclusion we can say, that more data improve the models.

| Model             | RSQ [Test set] | RMSE [Test set] | MAE [Test set] | Bias [Test set] |
|---------------|---------------|---------------|---------------|---------------|
| Linear Regression | 0.47           | 0.96 °C         | 0.75 °C        | 0.09 °C         |
| KNN               | 0.58           | 0.86 °C         | 0.63 °C        | 0.06 °C         |
| Random Forest     | 0.64           | 0.84 °C         | 0.59 °C        | 0.21 °C         |
| XGB Boost         | \-             | \-              | \-             | \-              |
| Neuronal Network  | \-             | \-              | \-             | \-              |

: **TABLE 4:** Overview of the evaluation of the models in the demo mode.

### Map

```{r}
source('../R/example_map.R')

```

# Discussion

## Data

## Methodology

## Conclusion

# Bibliography

[@burger2021]

[@gubler2021]

[@stocker2023]

[@wicki2018]

\
Oke, T. (2006), Initial Guidance to Obtain Representative Meteorological
Observations at\
Urban Sites: Instruments and Observing Methods. IOM Report No. 81., Canada:
World\
Meteorological Organization

\
Oke, T. R., Mills, G., Christen, A. and Voogt, J. A. (2017), Concepts. In:
Urban Climates,\
Cambridge University Press, p. 14--43
